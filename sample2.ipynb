{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tags:\n",
      "['quality', 'sound quality', 'sound', 'bass', 'battery', 'ear', 'backup', 'headphone', 'price']\n",
      "\n",
      "Overall Sentiment for Each Tag:\n",
      "quality: ‚úîÔ∏è Positive\n",
      "sound quality: ‚úîÔ∏è Positive\n",
      "sound: ‚úîÔ∏è Positive\n",
      "bass: ‚úîÔ∏è Positive\n",
      "battery: ‚úîÔ∏è Positive\n",
      "ear: ‚úîÔ∏è Positive\n",
      "backup: ‚úîÔ∏è Positive\n",
      "headphone: ‚úîÔ∏è Positive\n",
      "price: ‚úîÔ∏è Positive\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load Spacy for NLP\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load a sentiment analysis model\n",
    "sentiment_model = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "# Clean tag to remove generic words\n",
    "def clean_tag(tag):\n",
    "    return tag.lower().strip().replace(\"the \", \"\").replace(\"a \", \"\").replace(\"an \", \"\")\n",
    "\n",
    "# Extract tags dynamically with lemmatization\n",
    "def extract_tags_with_nlp(review):\n",
    "    doc = nlp(review)\n",
    "    tags = set()  # Use a set to avoid duplicates\n",
    "    \n",
    "    # Remove stop words before extracting noun chunks and other tokens\n",
    "    for chunk in doc.noun_chunks:\n",
    "        cleaned_tag = clean_tag(chunk.lemma_)\n",
    "        if cleaned_tag not in {\"it\", \"they\", \"we\", \"you\", \"ear\"} and not nlp.vocab[cleaned_tag].is_stop:  # Exclude stop words and pronouns\n",
    "            tags.add(cleaned_tag)\n",
    "    \n",
    "    for token in doc:\n",
    "        # Include NOUN and exclude stop words and punctuation\n",
    "        if token.pos_ == \"NOUN\" and not token.is_stop and not token.is_punct:\n",
    "            cleaned_tag = clean_tag(token.lemma_)\n",
    "            tags.add(cleaned_tag)\n",
    "\n",
    "    return list(tags)\n",
    "\n",
    "# Extract the sentence for context\n",
    "def get_context_sentence(review, tag):\n",
    "    doc = nlp(review)\n",
    "    for sent in doc.sents:\n",
    "        if tag in sent.text.lower():\n",
    "            return sent.text.strip()\n",
    "    return review\n",
    "\n",
    "# Custom rules for known negative phrases\n",
    "def check_custom_rules(tag, context):\n",
    "    negative_phrases = [\"stopped working\", \"disappointing\", \"doesn't work\", \"poor quality\"]\n",
    "    for phrase in negative_phrases:\n",
    "        if phrase in context.lower():\n",
    "            return \"NEGATIVE\"\n",
    "    return None\n",
    "\n",
    "# Analyze tags with improved sentiment accuracy\n",
    "def analyze_review_tags(review):\n",
    "    tags = extract_tags_with_nlp(review)\n",
    "    results = {}\n",
    "    for tag in tags:\n",
    "        # Extract the context sentence\n",
    "        context_sentence = get_context_sentence(review, tag)\n",
    "        # Check for custom rules first\n",
    "        custom_result = check_custom_rules(tag, context_sentence)\n",
    "        if custom_result:\n",
    "            results[tag] = custom_result\n",
    "            continue\n",
    "        # Use the sentiment model otherwise\n",
    "        input_text = f\"Review: {context_sentence} This is about {tag}.\"\n",
    "        sentiment = sentiment_model(input_text)[0]\n",
    "        results[tag] = sentiment[\"label\"]  # POSITIVE or NEGATIVE\n",
    "    return results\n",
    "\n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Extract tags from all reviews\n",
    "all_tags = []\n",
    "for review in data['review']:\n",
    "    all_tags.extend(extract_tags_with_nlp(review))\n",
    "\n",
    "# Count the frequency of each tag\n",
    "tag_counts = Counter(all_tags)\n",
    "\n",
    "# Define common words to exclude from tags\n",
    "common_words = {\"product\", \"item\", \"thing\", \"stuff\", \"something\"}\n",
    "\n",
    "# Determine the number of relevant tags dynamically based on a threshold\n",
    "threshold = 0.01  # Adjust the threshold as needed\n",
    "total_tags = sum(tag_counts.values())\n",
    "tags = [phrase for phrase, count in tag_counts.items() if count / total_tags >= threshold and phrase not in common_words]\n",
    "\n",
    "# Print the list of all generated tags\n",
    "print(\"Generated Tags:\")\n",
    "print(tags)\n",
    "\n",
    "# Associate tags with reviews\n",
    "def assign_tags(phrases):\n",
    "    return list(set(phrases) & set(tags))\n",
    "\n",
    "data['tags'] = data['review'].apply(lambda review: assign_tags(extract_tags_with_nlp(review)))\n",
    "\n",
    "# Perform sentiment analysis and add 'sentiment_indicator' column\n",
    "def get_sentiment_indicator(review):\n",
    "    analysis = TextBlob(review)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return '‚úîÔ∏è'\n",
    "    elif analysis.sentiment.polarity < 0:\n",
    "        return '‚ùå'\n",
    "    else:\n",
    "        return 'üòê'\n",
    "\n",
    "data['sentiment_indicator'] = data['review'].apply(get_sentiment_indicator)\n",
    "\n",
    "# Create a tag to reviews mapping\n",
    "tag_reviews = {tag: data[data['tags'].apply(lambda x: tag in x)] for tag in tags}\n",
    "\n",
    "# Aggregate sentiment indicators for each tag\n",
    "tag_sentiments = {}\n",
    "for tag, reviews in tag_reviews.items():\n",
    "    positive_count = (reviews['sentiment_indicator'] == '‚úîÔ∏è').sum()\n",
    "    negative_count = (reviews['sentiment_indicator'] == '‚ùå').sum()\n",
    "    total_count = positive_count + negative_count\n",
    "    \n",
    "    if positive_count > negative_count:\n",
    "        overall_sentiment = '‚úîÔ∏è Positive'\n",
    "    else:\n",
    "        overall_sentiment = '‚ùå Negative'\n",
    "    \n",
    "    tag_sentiments[tag] = overall_sentiment\n",
    "\n",
    "# Display the overall sentiment for each tag\n",
    "print(\"\\nOverall Sentiment for Each Tag:\")\n",
    "for tag, sentiment in tag_sentiments.items():\n",
    "    print(f\"{tag}: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reviews for tag 'battery':\n",
      "                                                 review\n",
      "2     awesome sound quality. pros 7-8 hrs of battery...\n",
      "5     Awsome sound powerful bass battery backup is a...\n",
      "12    I am using this headphone since 6 months, grea...\n",
      "14    Reson for 1 star : Sounds for alerts for conne...\n",
      "16    sound: its relay rock when I compare with othe...\n",
      "...                                                 ...\n",
      "9854  Sound quality is not so good.i received I spea...\n",
      "9857  Awsm sound quality.Vocals are clear.Average ba...\n",
      "9865  Sound and bass is very super and I am impresse...\n",
      "9914  Excellent battery backupSound quality also exc...\n",
      "9920  The product is very nice but initially it fits...\n",
      "\n",
      "[836 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "selected_tag = 'battery'  # Replace with any tag from the generated tags\n",
    "filtered_reviews = tag_reviews.get(selected_tag, pd.DataFrame())\n",
    "if not filtered_reviews.empty:\n",
    "    print(f\"\\nReviews for tag '{selected_tag}':\")\n",
    "    print(filtered_reviews[['review']])\n",
    "else:\n",
    "    print(f\"\\nNo reviews found for tag '{selected_tag}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streamlit==1.41.0\n",
      "pandas==2.2.3\n",
      "spacy==3.8.2\n",
      "textblob==0.18.0.post0\n",
      "collections is not installed\n",
      "requirements.txt has been generated.\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "# List of libraries to check\n",
    "libraries = [\n",
    "    \"en_core_web_sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl#sha256=1932429db727d4bff3deed6b34cfc05df17794f4a52eeb26cf8928f7c1a0fb85\",\n",
    "    \"streamlit\",\n",
    "    \"pandas\",\n",
    "    \"spacy\",\n",
    "    \"textblob\",\n",
    "    \"collections\"\n",
    "]\n",
    "\n",
    "# Function to get the version of a library\n",
    "def get_version(lib):\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(lib).version\n",
    "        return f\"{lib}=={version}\"\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        return f\"{lib} is not installed\"\n",
    "\n",
    "# Generate requirements.txt\n",
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    for lib in libraries:\n",
    "        if \"@\" in lib:\n",
    "            f.write(lib + \"\\n\")\n",
    "        else:\n",
    "            version_info = get_version(lib)\n",
    "            f.write(version_info + \"\\n\")\n",
    "            print(version_info)\n",
    "\n",
    "print(\"requirements.txt has been generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
